#!/bin/bash

#SBATCH --job-name=finetune-sweep     # Name of the job, will appear in monitoring tools
#SBATCH --array=0-4%5                     # Create a job array with indices 0 to 4, with a maximum of 5 jobs running concurrently
#SBATCH --time=7-00:00:00                 # Set a time limit for each job in the array (2 hours here)                  # Set a time limit for each job in the array (2 hours here)
#SBATCH --mem=20G                         # Request 20GB of memory for each job
#SBATCH --cpus-per-task=4                 # Request 4 CPU cores per task
#SBATCH --gres=gpu:1                      # Request 1 GPU per job (general resource scheduling)
#SBATCH --output=/home/mdellag/SplitNanoGPT/logs/%x-%A-%a.out  # Standard output log file; %x is job name, %A is job ID, %a is array index
#SBATCH --error=/home/mdellag/SplitNanoGPT/logs/%x-%A-%a.err   # Standard error log file; %x is job name, %A is job ID, %a is array index

# Define array of decay values as variables
QK_DECAYS=(-3.2 -1.6 -0.8 -0.4 -0.2)
WEIGHT_DECAY=0.1

ARG_FOR_ALL="--max_iters=25000 --wandb_project=openwebtext-finetune --weight_decay=$WEIGHT_DECAY --split=True --wandb_run_name=with_entropy"

cd /home/mdellag/SplitNanoGPT/

# Environment setup
source /home/mdellag/miniconda3/etc/profile.d/conda.sh    # Initialize Conda
conda deactivate                                          # Deactivate any existing environment
conda activate nanoGPTenv                                 # Activate the desired Conda environment


# Extract the specific command based on the SLURM array task ID and ARG_FOR_ALL
command="python3 /home/mdellag/SplitNanoGPT/split_train.py --qk_weight_decay=${QK_DECAYS[$SLURM_ARRAY_TASK_ID]} $ARG_FOR_ALL"

# Echo the command to stdout for transparency
echo "Running command: $command"

# Execute the command
$command